<!DOCTYPE html>
<html><head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>DataMUX: Data Multiplexing for Neural Networks - Karthik Narasimhan&#39;s Lab</title><link rel="icon" type="image/png" href="/images/favicon.ico">

	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="In this paper, we introduce data multiplexing (DataMUX), a technique that enables deep neural networks to process multiple inputs simultaneously using a single compact representation. DataMUX demonstrates that neural networks are capable of generating accurate predictions over mixtures of inputs, resulting in increased throughput with minimal extra memory requirements. Our approach uses two key components &ndash; 1) a multiplexing layer that performs a fixed linear transformation to each input before combining them to create a mixed representation of the same size as a single input, which is then processed by the base network, and 2) a demultiplexing layer that converts the base network&rsquo;s output back into independent representations before producing predictions for each input." />
	<meta property="og:image" content=""/>
	<meta property="og:title" content="DataMUX: Data Multiplexing for Neural Networks" />
<meta property="og:description" content="In this paper, we introduce data multiplexing (DataMUX), a technique that enables deep neural networks to process multiple inputs simultaneously using a single compact representation. DataMUX demonstrates that neural networks are capable of generating accurate predictions over mixtures of inputs, resulting in increased throughput with minimal extra memory requirements. Our approach uses two key components &ndash; 1) a multiplexing layer that performs a fixed linear transformation to each input before combining them to create a mixed representation of the same size as a single input, which is then processed by the base network, and 2) a demultiplexing layer that converts the base network&rsquo;s output back into independent representations before producing predictions for each input." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://example.org/posts/publications/murahari-22-datamux/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-07-16T00:00:00+00:00" />
<meta property="article:modified_time" content="2022-07-16T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="DataMUX: Data Multiplexing for Neural Networks"/>
<meta name="twitter:description" content="In this paper, we introduce data multiplexing (DataMUX), a technique that enables deep neural networks to process multiple inputs simultaneously using a single compact representation. DataMUX demonstrates that neural networks are capable of generating accurate predictions over mixtures of inputs, resulting in increased throughput with minimal extra memory requirements. Our approach uses two key components &ndash; 1) a multiplexing layer that performs a fixed linear transformation to each input before combining them to create a mixed representation of the same size as a single input, which is then processed by the base network, and 2) a demultiplexing layer that converts the base network&rsquo;s output back into independent representations before producing predictions for each input."/>
<script src="http://example.org/js/feather.min.js"></script>
	
	
        <link href="http://example.org/css/fonts.1f07d2398f08441d78602c672fb8cb2a0e9a2395c03b8d547ffbf1c8787e4dc6.css" rel="stylesheet">
	

	
	<link rel="stylesheet" type="text/css" media="screen" href="http://example.org/css/main.a7c0f144c33cc899db2a6bf2ed45af562fb88f5e218ca285f11e73d18f555b64.css" />
		<link id="darkModeStyle" rel="stylesheet" type="text/css" href="http://example.org/css/dark.2e992fe869b44f61fe1cc8a1ffb970084d2fc4a2bfb9d0f30cece368875edd65.css"  disabled />
	
	
	
</head>
<body>
        <div class="content"><header>
	<div class="main">
		<a href="http://example.org/">Karthik Narasimhan&#39;s Lab</a>
	</div>
	<nav>
		
		<a href="/posts">All Posts</a>&nbsp;&nbsp;&nbsp;
		
		<a href="/publications">Publications</a>&nbsp;&nbsp;&nbsp;
		
		<a href="/people">People</a>&nbsp;&nbsp;&nbsp;
		
		<a href="/tags">Tags</a>&nbsp;&nbsp;&nbsp;
		
		| <a id="dark-mode-toggle" onclick="toggleTheme()" href="">&nbsp;&nbsp;&nbsp;</a>
		<script src="http://example.org/js/themetoggle.js"></script>
		
	</nav>
</header>


<main>
	<article class="content-box">
		<div>
			<h1 style="margin-top:0.5em" class="title" >DataMUX: Data Multiplexing for Neural Networks</h1>
			<div class="meta">Posted on Jul 16, 2022</div>
			<div style="padding-top:10px"><span>
						<a href="https://vishvakmurahari.com/"><img class="author-list-photo"
								src="/images/people/murahari.jpeg"
							/>
						<span class="author-list-name" margin="0" padding="0">Vishvak Murahari</span></a>
					</span>
					&nbsp;<span>
						<a href="http://www.carlosejimenez.com/"><img class="author-list-photo"
								src="/images/people/carlosej.jpeg"
							/>
						<span class="author-list-name" margin="0" padding="0">Carlos E. Jimenez</span></a>
					</span>
					&nbsp;<span>
						<a href="https://runzhe-yang.science/"><img class="author-list-photo"
								src="/images/people/runzhey.jpeg"
							/>
						<span class="author-list-name" margin="0" padding="0">Runzhe Yang</span></a>
					</span>
					&nbsp;<span>
						<a href="https://www.cs.princeton.edu/~karthikn/"><img class="author-list-photo"
								src="/images/people/karthikn.jpeg"
							/>
						<span class="author-list-name" margin="0" padding="0">Karthik Narasimhan</span></a>
					</span>
					&nbsp;</div><div style="padding-top:10px;"><span class="supp-tag">
					<a href="https://github.com/princeton-nlp/DataMUX">GitHub</a>
				</span>
				<span class="supp-tag">
					<a href="https://arxiv.org/abs/2202.09318">Paper</a>
				</span>
				<span class="supp-tag">
					<a href="https://princeton-nlp.github.io/DataMUX/">Site</a>
				</span></div><div style="padding-top:10px;">
				
				<span class="post-tag">
					<a href="http://example.org//tags/machine-learning/">
						Machine Learning
					</a>
				</span>
				
				<span class="post-tag">
					<a href="http://example.org//tags/parallel-computing/">
						Parallel Computing
					</a>
				</span>
				
				<span class="post-tag">
					<a href="http://example.org//tags/computational-engineering/">
						Computational Engineering
					</a>
				</span>
				
			</div>
			
		</div>
		<hr class="post-separator"/>
		<section class="body post-content">
			<p>In this paper, we introduce data multiplexing (DataMUX), a technique that enables deep neural networks to process multiple inputs simultaneously using a single compact representation. DataMUX demonstrates that neural networks are capable of generating accurate predictions over mixtures of inputs, resulting in increased throughput with minimal extra memory requirements. Our approach uses two key components &ndash; 1) a multiplexing layer that performs a fixed linear transformation to each input before combining them to create a mixed representation of the same size as a single input, which is then processed by the base network, and 2) a demultiplexing layer that converts the base network&rsquo;s output back into independent representations before producing predictions for each input. We show the viability of DataMUX for different architectures (Transformers, and to a lesser extent MLPs and CNNs) across six different tasks spanning sentence classification, named entity recognition and image classification. For instance, DataMUX for Transformers can multiplex up to 20x/40x inputs, achieving 11x/18x increase in throughput with minimal absolute performance drops of &lt;2% and &lt;4% respectively on MNLI, a natural language inference task. We also provide a theoretical construction for multiplexing in self-attention networks and analyze the effect of various design elements in DataMUX.</p>

		</section>
	</article>
	
	<script
		type="text/javascript"
		async
		src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"
	>
	</script>
</main>



<script>
  feather.replace()
</script></div>
    </body>
</html>
